{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "from datetime import datetime, timedelta, timezone, time, date\n",
    "from itertools import product\n",
    "from functools import reduce\n",
    "from eclipses import query_graphql, produce_buses, produce_stops, find_eclipses, find_nadirs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_stops(dates, routes, directions=[], new_stops=[], timespan=(\"00:00\", \"23:59\")):\n",
    "    \"\"\"\n",
    "    get_stops\n",
    "\n",
    "    Description:\n",
    "        Returns every instance of a bus stopping at a given set of stops, on a given set of routes, during a given time period.\n",
    "\n",
    "    Parameters:\n",
    "        dates: an array of dates, formatted as strings in the form YYYY-MM-DD\n",
    "        routes: an array of routes, each represented as a string\n",
    "        directions: an array of strings representing the directions to filter\n",
    "        stops: an array of strings representing the stops to filter\n",
    "        times: a tuple with the start and end times (in UTC -8:00) as strings in the form HH:MM\n",
    "\n",
    "    Returns:\n",
    "        stops: a DataFrame, filtered by the given directions and stops, with the following columns:\n",
    "            VID: the vehicle ID\n",
    "            Time: a datetime object representing the date/time of the stop\n",
    "            Route: the route on which the stop occurred\n",
    "            Stop: the stop at which the stop occurred\n",
    "            Dir: the direction in which the stop occurred\n",
    "    \"\"\"\n",
    "    bus_stops = pd.DataFrame(columns = [\"VID\", \"DATE\", \"TIME\", \"SID\", \"DID\", \"ROUTE\"])\n",
    "\n",
    "    for route in routes:\n",
    "        stop_ids = [stop['id']\n",
    "            for stop\n",
    "            in requests.get(f\"http://restbus.info/api/agencies/sf-muni/routes/{route}\").json()['stops']]\n",
    "\n",
    "        for stop_id in stop_ids:\n",
    "            # check if stops to filter were provided, or if the stop_id is in the list of filtered stops\n",
    "            if (stop_id in new_stops) ^ (len(new_stops) == 0):\n",
    "                for date in dates:\n",
    "                    #print(f\"{datetime.now().strftime('%a %b %d %I:%M:%S %p')}: starting processing on stop {stop_id} on route {route} on {date}.\")\n",
    "                    start_time = int(datetime.strptime(f\"{date} {timespan[0]} -0800\", \"%Y-%m-%d %H:%M %z\").timestamp())*1000\n",
    "                    end_time   = int(datetime.strptime(f\"{date} {timespan[1]} -0800\", \"%Y-%m-%d %H:%M %z\").timestamp())*1000\n",
    "\n",
    "                    data = query_graphql(start_time, end_time, route)\n",
    "                    #print(f\"{datetime.now().strftime('%a %b %d %I:%M:%S %p')}: performed query.\")\n",
    "\n",
    "                    if data is None:  # API might refuse to cooperate\n",
    "                        print(\"API probably timed out\")\n",
    "                        continue\n",
    "                    elif len(data) == 0:  # some days somehow have no data\n",
    "                        print(f\"no data for {date}\")\n",
    "                        continue\n",
    "                    else:\n",
    "                        stops = produce_stops(data, route)\n",
    "                        #print(f\"{datetime.now().strftime('%a %b %d %I:%M:%S %p')}: produced stops.\")\n",
    "\n",
    "                        buses = produce_buses(data)\n",
    "                        #print(f\"{datetime.now().strftime('%a %b %d %I:%M:%S %p')}: produced buses.\")\n",
    "\n",
    "                        stop = stops[stops['SID'] == stop_id].squeeze()\n",
    "                        buses = buses[buses['DID'] == stop['DID']]\n",
    "\n",
    "                        eclipses = find_eclipses(buses, stop)\n",
    "                        #print(f\"{datetime.now().strftime('%a %b %d %I:%M:%S %p')}: found eclipses.\")\n",
    "\n",
    "                        nadirs = find_nadirs(eclipses)\n",
    "                        #print(f\"{datetime.now().strftime('%a %b %d %I:%M:%S %p')}: found nadirs.\")\n",
    "\n",
    "                        nadirs[\"TIME\"] = nadirs[\"TIME\"].apply(lambda x: datetime.fromtimestamp(x//1000, timezone(timedelta(hours = -8))))\n",
    "                        nadirs['DATE'] = nadirs['TIME'].apply(lambda x: x.date())\n",
    "                        nadirs['TIME'] = nadirs['TIME'].apply(lambda x: x.time())\n",
    "                        nadirs[\"SID\"] = stop_id\n",
    "                        nadirs[\"DID\"] = stop[\"DID\"]\n",
    "                        nadirs[\"ROUTE\"] = route\n",
    "                        bus_stops = bus_stops.append(nadirs, sort = True)\n",
    "                        #print(f\"{datetime.now().strftime('%a %b %d %I:%M:%S %p')}: finished processing.\")\n",
    "\n",
    "    # filter for directions\n",
    "    if len(directions) > 0:\n",
    "        bus_stops = bus_stops.loc[bus_stops['DID'].apply(lambda x: x in directions)]\n",
    "\n",
    "    # prepare timestamp data\n",
    "    bus_stops['timestamp'] = bus_stops[['DATE', 'TIME']].apply(lambda x: datetime.strptime(f\"{x['DATE'].isoformat()} {x['TIME'].isoformat()} -0800\",\n",
    "                                                                                       \"%Y-%m-%d %H:%M:%S %z\"), axis = 'columns')\n",
    "\n",
    "    return bus_stops\n",
    "\n",
    "\n",
    "# find the smallest nonnegative waiting time\n",
    "def absmin(series):\n",
    "    return series[series >= 0].min()\n",
    "\n",
    "\n",
    "# # input: df with entries from one day\n",
    "# # possible optimzation: sort df by timestamp, then pick first timestamp > minute for each minute (need to time to make sure but should be faster)\n",
    "def minimum_waiting_times(df, start_time, end_time, group):\n",
    "    minute_range = [start_time + timedelta(minutes=i) for i in range(\n",
    "        (end_time - start_time).seconds//60)]\n",
    "    wait_times = pd.DataFrame(columns=[])\n",
    "\n",
    "    for minute in minute_range:\n",
    "        # TODO (jtanquil): we get this error, see if you can fix it\n",
    "        # A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "        # Try using .loc[row_indexer,col_indexer] = value instead\n",
    "        # See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
    "        #   df['WAIT'] = df['timestamp'].apply(lambda x: (x - minute).total_seconds())\n",
    "        df['WAIT'] = df['timestamp'].apply(lambda x: (x - minute).total_seconds())\n",
    "        pivot = df[group + ['WAIT']].pivot_table(values = ['WAIT'], index = group, aggfunc = absmin)\n",
    "        pivot['TIME'] = minute\n",
    "        pivot = pivot.reset_index()\n",
    "        wait_times = wait_times.append(pivot, sort = True)\n",
    "\n",
    "    return wait_times\n",
    "\n",
    "def all_wait_times(df, timespan, group):\n",
    "    dates = df['DATE'].unique()\n",
    "    avg_over_pd = pd.DataFrame(columns = group + ['DATE', 'TIME', 'WAIT'])\n",
    "\n",
    "    for date in dates:\n",
    "        #print(f\"{datetime.now().strftime('%a %b %d %I:%M:%S %p')}: start processing {date}.\")\n",
    "        start_time = datetime.strptime(f\"{date.isoformat()} {timespan[0]} -0800\", \"%Y-%m-%d %H:%M %z\")\n",
    "        end_time   = datetime.strptime(f\"{date.isoformat()} {timespan[1]} -0800\", \"%Y-%m-%d %H:%M %z\")\n",
    "        daily_wait = minimum_waiting_times(df[df['DATE'] == date], start_time, end_time, group)\n",
    "        #print(f\"{datetime.now().strftime('%a %b %d %I:%M:%S %p')}: found waits for {date}.\")\n",
    "        #daily_wait = daily_wait.pivot_table(values = ['WAIT'], index = group).reset_index()\n",
    "        daily_wait['DATE'] = date\n",
    "        daily_wait['TIME'] = daily_wait['TIME'].apply(lambda x: x.time())\n",
    "        avg_over_pd = avg_over_pd.append(daily_wait, sort = True)\n",
    "\n",
    "    return avg_over_pd\n",
    "\n",
    "def quantiles(series):\n",
    "    return [np.percentile(series, i) for i in [5, 25, 50, 75, 95]]\n",
    "\n",
    "def get_summary_statistics(df, group):\n",
    "    waits = df.pivot_table(values = ['WAIT'], index = group, aggfunc = {'WAIT': [np.mean, np.std, quantiles]}).reset_index()\n",
    "    waits.columns = ['_'.join(col) if col[0] == 'WAIT' else ''.join(col) for col in waits.columns.values]\n",
    "    waits[[f\"{i}th percentile\" for i in [5, 25, 50, 75, 95]]] = waits['WAIT_quantiles'].apply(lambda x: pd.Series(x))\n",
    "    waits = waits.drop('WAIT_quantiles', axis = 1)\n",
    "    return waits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
